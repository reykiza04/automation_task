{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fraud Detection Mechanism\n",
        "1. 3TSS (3TimeSameStores) - Every Mapclub member makes 3 Transactions at the same store in 1 day.\n",
        "2. E150K (Earn More 150k) - Every Mapclub member who makes 1 Transaction and gets 150K points or more.\n",
        "3. 1T3DSS (1TimeIn3DaySameStores) - Every Mapclub member who makes 1 transaction at the same store within 3 consecutive days.\n",
        "4. 4TDS (4TimeDifferentStoreSameDay) - Every Mapclub member who makes 4 transactions at different stores in 1 day.\n",
        "5. 1ADC (1AreaDifferentConcept) - Every Mapclub member who makes transactions in 1 area and has 3 more diffrent concepts in 1 day.\n",
        "6. SCDS (SameConceptDiffrentStore) - Every Mapclub member who makes transactions in the same concept but with a diffrent store code in 1 day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, gc\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import sqlalchemy as sql\n",
        "from sqlalchemy.sql import text\n",
        "from sqlalchemy.pool import NullPool\n",
        "from urllib.parse import quote\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "from pandasql import sqldf\n",
        "from dateutil import rrule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "username = \"\"\n",
        "password = \"\"\n",
        "host = \"\" # new\n",
        "\n",
        "connect_string_dwhdb = 'mysql://'+username+':'+quote(password)+'@'+host+'/?charset=utf8mb4'\n",
        "sql_engine_dwhdb = sql.create_engine(connect_string_dwhdb, poolclass=NullPool)\n",
        "sql_engine_dwhdb.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chosee what date to process manually (date_snap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# tahon, bulan, tanggal\n",
        "date_obj = datetime.date(2023, 11, 17)\n",
        "date_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# date_str = \"11 September 2023\"\n",
        "# date_obj = datetime.datetime.strptime(date_str, \"%d %B %Y\").date()\n",
        "# date_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "partition_to_execute = 'SP{0}'.format(date_obj.strftime(\"%Y%m\")) + ',' + 'SP{0}'.format((date_obj + datetime.timedelta(days=-3)).strftime(\"%Y%m\"))\n",
        "\n",
        "partition_to_execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "end_date_trx = date_obj.strftime(\"%Y-%m-%d\")\n",
        "start_date_trx = (date_obj + datetime.timedelta(days=-3)).strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "start_date_trx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "end_date_trx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "q = f\"\"\" \n",
        "SELECT a.internalreference\n",
        "FROM mardiyan.LoyaltyMemberWalletTransactions PARTITION({partition_to_execute}) as a\n",
        "WHERE a.type LIKE \"%cancel%\" AND CAST(a.TransactionTime AS DATE) BETWEEN '{start_date_trx}' AND '{end_date_trx}' \n",
        "\"\"\"\n",
        "gclub_Cancel = pd.read_sql(text(q), sql_engine_dwhdb)\n",
        "\n",
        "q = (f\"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberWalletTransactionID, a.`Type`, a.TransactionTime, a.LocationReference, b.ConceptName, b.SBUGroup,\n",
        "b.Area, b.Province, b.City, a.PointValue, a.Reference, c.ChannelReference,\n",
        "c.LoyaltyPayServicePayTransactionID, c.RuleServiceTransactionID, c.WalletServiceEarnTransactionID, c.WalletServiceBurnTransactionID,\n",
        "d.RetailValueBeforeTax, ROUND(SUM(e.RetailValueBeforeTax),0) AS RetailValueBeforeTaxItem,\n",
        "if(d.RetailValueBeforeTax < 1000,IFNULL(ROUND(SUM(e.RetailValueBeforeTax),0),d.RetailValueBeforeTax), d.RetailValueBeforeTax) AS NewRetailValueBeforeTax, c.RetailValueAfterTax,\n",
        "case when right(a.LocationReference,2) = 'df' then 'MonoBrand'\n",
        "when a.LocationReference IN ('M901') then 'MonoBrand'\n",
        "when a.LocationReference IN ('M902') then 'DIGIMAP Shopee'\n",
        "when c.ChannelReference IN ('MAPEMALL') then 'Mapemall'\n",
        "ELSE 'store' END AS typeStore\n",
        "FROM mardiyan.LoyaltyMemberWalletTransactions PARTITION({partition_to_execute}) AS a\n",
        "LEFT JOIN mardiyan.MasterStoresV2 AS b ON a.LocationReference = b.StoreCode \n",
        "-- if(a.LocationReference = 'CV85', 'CV40', a.LocationReference) = b.StoreCode \n",
        "AND CAST(a.TransactionTime AS DATE)\n",
        "    BETWEEN CAST(b.ValidFrom AS DATE) AND CAST(b.ValidUntil AS DATE)\n",
        "LEFT JOIN mardiyan.LoyaltyPayServicePayTransactions PARTITION({partition_to_execute}) AS c ON a.LoyaltyMemberWalletTransactionID = c.WalletServiceEarnTransactionID \n",
        "LEFT JOIN mardiyan.LoyaltyRuleServiceTransactionResults PARTITION({partition_to_execute}) AS d ON c.RuleServiceTransactionID = d.TransactionID\n",
        "LEFT JOIN mardiyan.LoyaltyRuleServiceTransactionBasketItems PARTITION({partition_to_execute}) AS e ON c.RuleServiceTransactionID = e.TransactionID\n",
        "WHERE a.`Type` = 'EARN' AND a.InternalReference IS NULL AND CAST(a.TransactionTime AS DATE) -- BETWEEN '2023-04-24' AND '2023-04-30'\n",
        "    BETWEEN '{start_date_trx}' AND '{end_date_trx}'  \n",
        "    -- BETWEEN (SELECT DATE_SUB(CURDATE(),INTERVAL 3 DAY)) AND (SELECT DATE_SUB(CURDATE(),INTERVAL 1 DAY)) \n",
        "-- AND a.LoyaltyMemberWalletTransactionID NOT IN (SELECT internalreference FROM gclub.cancel) -- AND date(a.CreatedAt) <= '2021-12-05'\n",
        "GROUP BY a.LoyaltyMemberWalletTransactionID, c.LoyaltyPayServicePayTransactionID, c.RuleServiceTransactionID\n",
        "ORDER BY a.TransactionTime\n",
        ";\n",
        "\"\"\")\n",
        "gclub_Earn = pd.read_sql(text(q), sql_engine_dwhdb, parse_dates=['TransactionTime'])\n",
        "\n",
        "q = (f\"\"\"\n",
        "SELECT a.MemberID, a.LoyaltyMemberWalletTransactionID, a.`Type`, a.TransactionTime, a.LocationReference, b.ConceptName, b.SBUGroup,\n",
        "b.Area, b.Province, b.City, a.PointValue, a.Reference, c.ChannelReference,\n",
        "c.LoyaltyPayServicePayTransactionID, c.RuleServiceTransactionID, c.WalletServiceEarnTransactionID, c.WalletServiceBurnTransactionID,\n",
        "d.RetailValueBeforeTax, ROUND(SUM(e.RetailValueBeforeTax),0) AS RetailValueBeforeTaxItem,\n",
        "if(d.RetailValueBeforeTax < 1000,IFNULL(ROUND(SUM(e.RetailValueBeforeTax),0),d.RetailValueBeforeTax), d.RetailValueBeforeTax) AS NewRetailValueBeforeTax, c.RetailValueAfterTax,\n",
        "case when right(a.LocationReference,2) = 'df' then 'MonoBrand'\n",
        "when a.LocationReference IN ('M901') then 'MonoBrand'\n",
        "when a.LocationReference IN ('M902') then 'DIGIMAP Shopee'\n",
        "when c.ChannelReference IN ('MAPEMALL') then 'Mapemall'\n",
        "ELSE 'store' END AS typeStore\n",
        "FROM mardiyan.LoyaltyMemberWalletTransactions PARTITION({partition_to_execute}) AS a\n",
        "LEFT JOIN mardiyan.MasterStoresV2 AS b ON a.LocationReference = b.StoreCode \n",
        "-- if(a.LocationReference = 'CV85', 'CV40', a.LocationReference) = b.StoreCode \n",
        "AND CAST(a.TransactionTime AS DATE)\n",
        "    BETWEEN CAST(b.ValidFrom AS DATE) AND CAST(b.ValidUntil AS DATE)\n",
        "LEFT JOIN mardiyan.LoyaltyPayServicePayTransactions PARTITION({partition_to_execute}) AS c ON a.LoyaltyMemberWalletTransactionID = c.WalletServiceBurnTransactionID \n",
        "LEFT JOIN mardiyan.LoyaltyRuleServiceTransactionResults PARTITION({partition_to_execute}) AS d ON c.RuleServiceTransactionID = d.TransactionID\n",
        "LEFT JOIN mardiyan.LoyaltyRuleServiceTransactionBasketItems PARTITION({partition_to_execute}) AS e ON c.RuleServiceTransactionID = e.TransactionID\n",
        "WHERE a.`Type` = 'BURN' AND a.InternalReference IS NULL AND CAST(a.TransactionTime AS DATE) -- BETWEEN '2023-04-24' AND '2023-04-30'\n",
        "    BETWEEN '{start_date_trx}' AND '{end_date_trx}'  \n",
        "    -- BETWEEN (SELECT DATE_SUB(CURDATE(),INTERVAL 3 DAY)) AND (SELECT DATE_SUB(CURDATE(),INTERVAL 1 DAY)) \n",
        "-- AND a.LoyaltyMemberWalletTransactionID NOT IN (SELECT internalreference FROM gclub.cancel) -- AND date(a.CreatedAt) <= '2021-12-05'\n",
        "GROUP BY a.LoyaltyMemberWalletTransactionID, c.LoyaltyPayServicePayTransactionID, c.RuleServiceTransactionID\n",
        "ORDER BY a.TransactionTime\n",
        ";\n",
        "\"\"\")\n",
        "gclub_Burn = pd.read_sql(text(q), sql_engine_dwhdb, parse_dates=['TransactionTime'])\n",
        "\n",
        "gclub_Earn = gclub_Earn[~(gclub_Earn['LoyaltyMemberWalletTransactionID'].isin(gclub_Cancel['internalreference']))]\n",
        "gclub_Burn = gclub_Burn[~(gclub_Burn['LoyaltyMemberWalletTransactionID'].isin(gclub_Cancel['internalreference']))]\n",
        "\n",
        "q = \"\"\"\n",
        "SELECT * FROM -- PROSES FILTER SALES VALUE TRANSACTION DARI TRANSACTION BURN (HANYA AMBIL YG FULL REDEEM)\n",
        "(\tSELECT a.MemberID, a.LoyaltyMemberWalletTransactionID, a.`Type`, a.TransactionTime, a.LocationReference, a.ConceptName, a.SBUGroup,\n",
        "\ta.Area, a.Province, a.City, a.PointValue, a.Reference, a.ChannelReference,\n",
        "\ta.LoyaltyPayServicePayTransactionID, a.RuleServiceTransactionID, a.WalletServiceEarnTransactionID, a.WalletServiceBurnTransactionID,\n",
        "\ta.RetailValueBeforeTax, a.RetailValueBeforeTaxItem, \n",
        "\tIIF(a.NewRetailValueBeforeTax <= 0, ROUND(a.RetailValueAfterTax / 1.1), \n",
        "\t\tIIF(a.NewRetailValueBeforeTax IS NULL, ROUND(a.RetailValueAfterTax / 1.1), a.NewRetailValueBeforeTax)) AS NewRetailValueBeforeTax, a.RetailValueAfterTax, a.typeStore \n",
        "\tFROM gclub_Burn AS a\n",
        "\tLEFT JOIN gclub_Earn AS b ON a.MemberID = b.MemberID AND a.LocationReference = b.LocationReference AND DATE(a.TransactionTime) = DATE(b.TransactionTime)\n",
        "\t\t-- AND CAST(a.TransactionTime AS DATE) = CAST(b.TransactionTime AS DATE)\n",
        "\tWHERE \n",
        "\tIIF(-- KONDISI UNTUK MEMFILTER TRANSAKSI FULL REDEEM\n",
        "\t\ta.MemberID = b.MemberID AND a.LocationReference = b.LocationReference AND DATE(a.TransactionTime) = DATE(b.TransactionTime),\n",
        "\t\t\t-- AND CAST(a.TransactionTime AS DATE) = CAST(b.TransactionTime AS DATE),\n",
        "\t\t\tIIF(a.WalletServiceEarnTransactionID IS NOT NULL AND a.Reference IS NOT NULL, 'No', -- pli\n",
        "\t\t\t\tIIF(a.WalletServiceEarnTransactionID IS NULL AND a.Reference IS NULL, 'No', 'Yes')), 'Yes') = 'Yes'\n",
        "\tGROUP BY a.MemberID, a.LoyaltyMemberWalletTransactionID, a.TransactionTime\n",
        "\tORDER BY a.MemberID, a.LoyaltyMemberWalletTransactionID, a.TransactionTime\n",
        ") AS aa \n",
        ";\n",
        "\"\"\"\n",
        "gclub_TempSalesTrxValueEarnBurnA = sqldf(q, locals())\n",
        "\n",
        "gclub_TempSalesTrxValueEarnBurn = pd.concat([gclub_Earn, gclub_TempSalesTrxValueEarnBurnA])\n",
        "gclub_TempSalesTrxValueEarnBurn['TransactionTime'] = pd.to_datetime(gclub_TempSalesTrxValueEarnBurn['TransactionTime'])\n",
        "\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.RuleServiceTransactionID, a.`Type`, a.LocationReference, a.SBUGroup, a.ConceptName, a.TransactionTime,\n",
        "strftime('%m', a.TransactionTime) AS Month, strftime('%Y', a.TransactionTime) AS YEAR,\n",
        "-- MONTH() , YEAR(a.TransactionTime) ,\n",
        "case\n",
        "\twhen LENGTH(a.Reference) = 43 then 'NO'\n",
        "\twhen a.Reference LIKE '%adj%' then 'NO'\n",
        "\twhen a.Reference LIKE '%inject%' then 'NO'\n",
        "\twhen a.Reference LIKE '%point%' then 'NO'\n",
        "\twhen a.Reference LIKE '%IGStory%' then 'NO'\n",
        "\twhen a.Reference LIKE '%test%' then 'NO'\n",
        "\twhen a.Reference IS NULL AND a.NewRetailValueBeforeTax = 0 then 'NO'\n",
        "\t-- when a.NewRetailValueBeforeTax = 0 then 'NO'\n",
        "\twhen a.NewRetailValueBeforeTax is NULL then 'NO'\t\n",
        "\tELSE 'YES' \n",
        "END AS Keterangan,\n",
        "a.RetailValueBeforeTax, a.RetailValueBeforeTaxItem, a.NewRetailValueBeforeTax, a.PointValue, a.Reference, a.ChannelReference, a.Area, \n",
        "a.City, a.Province, a.TypeStore\n",
        "FROM gclub_TempSalesTrxValueEarnBurn AS a\n",
        "WHERE -- a.SBUGroup IS NULL AND \n",
        "case\n",
        "\twhen LENGTH(a.Reference) = 43 then 'NO'\n",
        "\twhen a.Reference LIKE '%adj%' then 'NO'\n",
        "\twhen a.Reference LIKE '%inject%' then 'NO'\n",
        "\twhen a.Reference LIKE '%point%' then 'NO'\n",
        "\twhen a.Reference LIKE '%IGStory%' then 'NO'\n",
        "\twhen a.Reference LIKE '%test%' then 'NO'\n",
        "\twhen a.Reference IS NULL AND a.NewRetailValueBeforeTax = 0 then 'NO'\n",
        "\t-- when a.NewRetailValueBeforeTax = 0 then 'NO'\n",
        "\twhen a.NewRetailValueBeforeTax is NULL then 'NO'\t\n",
        "\tELSE 'YES' \n",
        "END = 'YES' \n",
        "-- GROUP BY  a.SBUGroup, a.ConceptName, MONTH(a.TransactionTime), YEAR(a.TransactionTime)\n",
        ";\n",
        "\"\"\"\n",
        "gclub_SalesTrxValueEarnBurn = sqldf(q, locals())\n",
        "\n",
        "gclub_SalesTrxValueEarnBurn['TransactionTime'] = pd.to_datetime(gclub_SalesTrxValueEarnBurn['TransactionTime'])\n",
        "\n",
        "gclub_SalesTrxValueEarnBurn.to_sql(con=sql_engine_dwhdb,\n",
        "    name='WeeklyChannelFraud',\n",
        "    schema='gclub', # re-check\n",
        "    index=False,\n",
        "    if_exists='replace')\n",
        "\n",
        "del gclub_Cancel\n",
        "del gclub_Earn\n",
        "del gclub_Burn\n",
        "del gclub_TempSalesTrxValueEarnBurnA\n",
        "del gclub_TempSalesTrxValueEarnBurn\n",
        "\n",
        "## Process Data\n",
        "### Raw Data\n",
        "q = f\"\"\" \n",
        "SELECT a.MemberID, c.LoyaltyMemberID, CONCAT(c.FirstName, \" \", c.LastName) MemberName, \n",
        "\tDATE(c.BirthDate) BirthDate, c.Address1, c.Address2, c.Phone, c.Email,\n",
        "\tDATE(c.EnrollmentDate) EnrollmentDate, c.EnrollmentLocationReference EnrollmentStore,\n",
        "\td.TotalPointsEarned, d.TotalPointsBurned, DATE(a.TransactionTime) TransactionTime, a.LocationReference StoreLocation, \n",
        "\tb.EarnedPoints EarnedPoints, a.RuleServiceTransactionID, a.NewRetailValueBeforeTax\n",
        "FROM gclub.WeeklyChannelFraud AS a\n",
        "LEFT JOIN mardiyan.LoyaltyRuleServiceTransactionResults PARTITION({partition_to_execute}) AS b \n",
        "\tON a.RuleServiceTransactionID = b.TransactionID\n",
        "LEFT JOIN mardiyan.LoyaltyMemberEnrollmentServiceMembers AS c ON \n",
        "\ta.MemberID = c.LoyaltyMemberEnrollmentServiceMemberID\n",
        "LEFT JOIN mardiyan.LoyaltyMemberWallets d\n",
        "\tON a.MemberID = d.LoyaltyMemberWalletID \n",
        ";\n",
        "\"\"\"\n",
        "dx = pd.read_sql_query(text(q), sql_engine_dwhdb, parse_dates=['BirthDate', 'EnrollmentDate', 'TransactionTime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "df = dx[(pd.to_datetime(dx['TransactionTime'].dt.date) >= dx['TransactionTime'].max()) & (pd.to_datetime(dx['TransactionTime'].dt.date) <= dx['TransactionTime'].max())].copy()\n",
        "dfC = dx[(pd.to_datetime(dx['TransactionTime'].dt.date) >= dx['TransactionTime'].min()) & (pd.to_datetime(dx['TransactionTime'].dt.date) <= dx['TransactionTime'].max())].copy()\n",
        "dfC.sort_values('TransactionTime', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Data Point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Point A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Point A - Thor - 3TimeSameStores\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "    a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore,\n",
        "    a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM df AS a\n",
        "GROUP BY a.MemberID, a.StoreLocation, DATE(a.TransactionTime)\n",
        "HAVING COUNT(DISTINCT a.RuleServiceTransactionID) >= 3\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelA = sqldf(q, locals())\n",
        "\n",
        "dfChannelA.iloc[:, [3,8,12]] = dfChannelA.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Point B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Point B - Poseidon - Earn More 150k\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore, a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM (\n",
        "    SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "        a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "        a.EnrollmentDate, a.EnrollmentStore,\n",
        "        a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "        a.EarnedPoints, a.RuleServiceTransactionID\n",
        "    FROM df AS a\n",
        "    WHERE a.EarnedPoints > 150000 AND a.NewRetailValueBeforeTax > 0 \n",
        ")as a\n",
        "GROUP BY a.MemberID\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelB = sqldf(q, locals())\n",
        "\n",
        "dfChannelB.iloc[:, [3,8,12]] = dfChannelB.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Point C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Point C - Asce - 1TimeIn3DaySameStores\n",
        "# First Filter - Get >= 3 Trx\n",
        "gclub_PointCandD = dfC.groupby(['MemberID']).agg({\n",
        "    'RuleServiceTransactionID' : pd.Series.nunique\n",
        "}).reset_index()\n",
        "\n",
        "memberMore3 = gclub_PointCandD[gclub_PointCandD['RuleServiceTransactionID'] >=3]['MemberID']\n",
        "\n",
        "rawC = dfC[dfC['MemberID'].isin(memberMore3)][['MemberID', 'StoreLocation', 'TransactionTime']].copy()\n",
        "rawC['TransactionTime'] = rawC['TransactionTime'].dt.date\n",
        "rawC['TransactionTime'] = pd.to_datetime(rawC['TransactionTime'])\n",
        "rawC.drop_duplicates(subset=['MemberID', 'StoreLocation', 'TransactionTime'], keep='last', inplace=True)\n",
        "rawC.sort_values(by=['MemberID', 'StoreLocation', 'TransactionTime'], inplace=True, ascending=False)\n",
        "rawC.reset_index(drop=True, inplace=True)\n",
        "# Search Per Day\n",
        "memberPointC = []\n",
        "# x = 0\n",
        "for i in rawC['MemberID'].unique():\n",
        "    df_1 = rawC[rawC['MemberID'] == i]\n",
        "    for k in df_1['StoreLocation'].unique():\n",
        "        x = 0\n",
        "        df_2 = df_1[df_1['StoreLocation'] == k]\n",
        "        for j in range(len(df_2)-1):\n",
        "            if((df_2.iloc[(j), -1].day - df_2.iloc[(j+1), -1].day) == 1) :\n",
        "                x+=1 \n",
        "            else :\n",
        "                x = 0\n",
        "            if x == 2:\n",
        "                memberPointC.append(i)\n",
        "                break\n",
        "\n",
        "df_memberPointC = pd.DataFrame(memberPointC, columns=['MemberID'])\n",
        "\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "    a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore,\n",
        "    a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM dfC AS a\n",
        "GROUP BY a.MemberID, a.StoreLocation\n",
        "ORDER BY a.MemberID, a.StoreLocation\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelC = sqldf(q, locals())\n",
        "\n",
        "dfChannelC.iloc[:, [3,8,12]] = dfChannelC.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "dfChannelC = dfChannelC[dfChannelC['MemberID'].isin(df_memberPointC['MemberID'])].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Point D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Point D - Enma - 4TimeDifferentStoreSameDay\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "    a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore,\n",
        "    a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM df AS a\n",
        "GROUP BY a.MemberID, DATE(a.TransactionTime)\n",
        "HAVING COUNT(DISTINCT a.StoreLocation) >= 4\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelD = sqldf(q, locals())\n",
        "\n",
        "dfChannelD.iloc[:, [3,8,12]] = dfChannelD.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Point F & G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Point F & G - Nika & Loki - 1AreaDifferentConcept & 1ConceptDiffrentStore\n",
        "#### Raw Data F & G\n",
        "dfPointFandG = gclub_SalesTrxValueEarnBurn[(gclub_SalesTrxValueEarnBurn['TransactionTime'] >= date_obj.strftime('%Y-%m-%d')) & \n",
        "                        (gclub_SalesTrxValueEarnBurn['TransactionTime'] <= date_obj.strftime('%Y-%m-%d'))][['MemberID', \n",
        "                            'RuleServiceTransactionID', 'TransactionTime', 'LocationReference', 'Area', 'ConceptName']].copy()   \n",
        "                            \n",
        "dfPointFandG = gclub_SalesTrxValueEarnBurn[(pd.to_datetime(gclub_SalesTrxValueEarnBurn['TransactionTime'].dt.date) >= str((date_obj + datetime.timedelta(days=-1)).strftime('%Y-%m-%d'))) & (pd.to_datetime(gclub_SalesTrxValueEarnBurn['TransactionTime'].dt.date) <= str((date_obj + datetime.timedelta(days=-1)).strftime('%Y-%m-%d')))][['MemberID', 'RuleServiceTransactionID', 'TransactionTime', 'LocationReference', 'Area', 'ConceptName']].copy()\n",
        "                            \n",
        "dfPointFandG.sort_values(by=['TransactionTime'], inplace=True)\n",
        "dfPointFandG['TransactionTime'] = dfPointFandG['TransactionTime'].dt.date\n",
        "dfPointFandG['TransactionTime'] = pd.to_datetime(dfPointFandG['TransactionTime'])\n",
        "\n",
        "# Cleaning data to 1 concept name\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].apply(lambda x : 'Samsonite' if ((x == 'Samsonite DOS RPA') or (x == 'Samsonite MAP') or (x == 'Samsonite RPA')) else x)\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' RPA', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' MGI', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' MGR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' BKMR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' CMIR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' MDFR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' OFAR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' PAR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' PBPR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' SDVR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' SGR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' SFAR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' MFAR', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' MAP', '')\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].str.replace(' PFA', '')\n",
        "\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].apply(lambda x : 'Kinokuniya' if (x == 'Kinokuniya Pustaka') else x)\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].apply(lambda x : 'Maxmara' if (x == 'Maxmara Weekend') else x)\n",
        "dfPointFandG['ConceptName'] = dfPointFandG['ConceptName'].apply(lambda x : 'Tommy Hilfiger' if (x == 'Tommy Hilfiger ') else x)\n",
        "\n",
        "# Drop data yang duplicate (seusai dengan channel yang diminta)\n",
        "dfX = dfPointFandG.drop_duplicates(subset=['MemberID', 'Area', 'ConceptName', 'TransactionTime'])\n",
        "dfY = dfPointFandG.drop_duplicates(subset=['MemberID', 'ConceptName', 'LocationReference', 'TransactionTime'])\n",
        "\n",
        "# Gabungin unique concept name & ambil berapa total unique concept name nya\n",
        "dfXGP1 = dfX.groupby(['MemberID', 'Area', 'TransactionTime'])['ConceptName'].apply(lambda x: ' | '.join(x)).reset_index()\n",
        "dfXGP2 = dfX.groupby(['MemberID', 'Area', 'TransactionTime']).agg({'ConceptName' : pd.Series.nunique}).reset_index()\n",
        "\n",
        "dfYGP1 = dfY.groupby(['MemberID', 'ConceptName', 'TransactionTime'])['LocationReference'].apply(lambda x: ' | '.join(x)).reset_index()\n",
        "dfYGP2 = dfY.groupby(['MemberID', 'ConceptName', 'TransactionTime']).agg({'LocationReference' : pd.Series.nunique}).reset_index()\n",
        "\n",
        "# Gabungin / left join \n",
        "dfXGP = pd.merge(dfXGP1, dfXGP2, on=['MemberID', 'Area', 'TransactionTime'])\n",
        "dfYGP = pd.merge(dfYGP1, dfYGP2, on=['MemberID', 'ConceptName', 'TransactionTime'])\n",
        "\n",
        "# rename column name\n",
        "dfXGP.rename(columns={'ConceptName_x': 'ConceptName', 'ConceptName_y': 'NumConceptName'}, inplace=True)\n",
        "dfYGP.rename(columns={'LocationReference_x': 'LocationReference', 'LocationReference_y': 'NumLocationReference'}, inplace=True)\n",
        "\n",
        "# get only valid data (Point F)\n",
        "dfXGP = dfXGP[dfXGP['NumConceptName'] >=3]\n",
        "dfXGPF1 = dfXGP.groupby(['MemberID'])['Area'].apply(lambda x: ' <> '.join(x)).reset_index()\n",
        "dfXGPF2 = dfXGP.groupby(['MemberID'])['ConceptName'].apply(lambda x: ' <> '.join(x)).reset_index()\n",
        "dfXGPF3 = dfXGP.groupby(['MemberID']).agg({'Area' : pd.Series.nunique, 'NumConceptName' : np.sum}).reset_index() # catatan untuk numConcept agak tdk valid, karena tdk unique concept\n",
        "dfXGPF = pd.merge(dfXGPF1, dfXGPF2, on=['MemberID'])\n",
        "dfXGPF = pd.merge(dfXGPF, dfXGPF3, on=['MemberID'])\n",
        "dfXGPF.rename(columns={'Area_x': 'Area', 'Area_y': 'NumArea'}, inplace=True)\n",
        "dfXGPF = dfXGPF[dfXGPF['NumConceptName'] >= 3]\n",
        "dfYGP = dfYGP[dfYGP['NumLocationReference'] >= 3]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Point F & G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "#### Point F\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "    a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore,\n",
        "    a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM df AS a\n",
        "GROUP BY a.MemberID\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelF = sqldf(q, locals())\n",
        "\n",
        "dfChannelF.iloc[:, [3,8,12]] = dfChannelF.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "dfChannelF = dfChannelF[dfChannelF['MemberID'].isin(dfXGPF['MemberID'])].copy()\n",
        "\n",
        "#### Point G\n",
        "q = \"\"\" \n",
        "SELECT a.MemberID, a.LoyaltyMemberID, a.MemberName, \n",
        "    a.BirthDate, a.Address1, a.Address2, a.Phone, a.Email,\n",
        "    a.EnrollmentDate, a.EnrollmentStore,\n",
        "    a.TotalPointsEarned, a.TotalPointsBurned, a.TransactionTime, a.StoreLocation, \n",
        "    SUM(a.EarnedPoints) EarnedPoints, COUNT(DISTINCT a.RuleServiceTransactionID) TotalTransactions\n",
        "FROM df AS a\n",
        "GROUP BY a.MemberID\n",
        ";\n",
        "\"\"\"\n",
        "dfChannelG = sqldf(q, locals())\n",
        "\n",
        "dfChannelG.iloc[:, [3,8,12]] = dfChannelG.iloc[:, [3,8,12]].apply(pd.to_datetime)\n",
        "dfChannelG = dfChannelG[dfChannelG['MemberID'].isin(dfYGP['MemberID'])].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Status Member"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "### Status All Member\n",
        "q = \"\"\" \n",
        "SELECT a.LoyaltyMemberID, a.Status\n",
        "FROM (\n",
        "SELECT DISTINCT a.LoyaltyMemberID, '3TSS' AS Status\n",
        "FROM dfChannelA AS a\n",
        "UNION ALL \n",
        "SELECT DISTINCT a.LoyaltyMemberID, 'E150K'\n",
        "FROM dfChannelB AS a\n",
        "UNION ALL \n",
        "SELECT DISTINCT a.LoyaltyMemberID, '1T3DSS' AS Status\n",
        "FROM dfChannelC AS a\n",
        "UNION ALL \n",
        "SELECT DISTINCT a.LoyaltyMemberID, '4TDS' AS Status\n",
        "FROM dfChannelD AS a\n",
        "UNION ALL \n",
        "SELECT DISTINCT a.LoyaltyMemberID, '1ADC'\n",
        "FROM dfChannelF AS a\n",
        "UNION ALL \n",
        "SELECT DISTINCT a.LoyaltyMemberID, 'SCDS' AS Status\n",
        "FROM dfChannelG AS a\n",
        ") AS a \n",
        ";\n",
        "\"\"\"\n",
        "statusMember = sqldf(q, locals())\n",
        "statusMemberGP1 = statusMember.groupby(['LoyaltyMemberID'])['Status'].apply(lambda x: ','.join(x)).reset_index()\n",
        "statusMemberGP2 = statusMember.groupby(['LoyaltyMemberID']).agg({'Status' : pd.Series.nunique}).reset_index()\n",
        "dfStatusGP = pd.merge(statusMemberGP1, statusMemberGP2, on=['LoyaltyMemberID'])\n",
        "dfStatusGP.rename(columns={'Status_x': 'Status', 'Status_y': 'NumStatus'}, inplace=True)\n",
        "## Final Recap (To Excel & Status) - Excel Part 1\n",
        "dfChannelF = dfChannelF.merge(dfXGPF,left_on='MemberID',right_on='MemberID', how='left')\n",
        "dfChannelG = dfChannelG.merge(dfYGP,left_on='MemberID',right_on='MemberID', how='left')\n",
        "dfChannelG.drop_duplicates(subset='MemberID', inplace=True)\n",
        "\n",
        "# Every Channel Give Status\n",
        "dfChannelA['Channels'] = '3TSS'\n",
        "dfChannelB['Channels'] = 'E150K'\n",
        "dfChannelC['Channels'] = '1T3DSS'\n",
        "dfChannelD['Channels'] = '4TDS'\n",
        "dfChannelF['Channels'] = '1ADC'\n",
        "dfChannelG['Channels'] = 'SCDS'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rename Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Rename columns data\n",
        "dataGabunganA = pd.concat([dfChannelA,dfChannelB,dfChannelC,dfChannelD])\n",
        "dataGabunganA.drop(columns=['Address2'], axis=1, inplace=True)\n",
        "dataGabunganA.rename(columns={\n",
        "    'MemberName' : 'Name',\n",
        "    'Address1' : 'Address',\n",
        "    'TotalPointsEarned' :  'Points Earned',\n",
        "    'TotalPointsBurned' : 'Points Burned',\n",
        "    'TransactionTime' : 'TransactionDate',\n",
        "    'EarnedPoints' : 'Base Earned Points'\n",
        "}, inplace=True)\n",
        "\n",
        "# Rename columns data\n",
        "dfChannelF.drop(columns=['Address2', 'NumArea'], axis=1, inplace=True)\n",
        "dfChannelF.rename(columns={\n",
        "    'MemberName' : 'Name',\n",
        "    'Address1' : 'Address',\n",
        "    'TotalPointsEarned' :  'Points Earned',\n",
        "    'TotalPointsBurned' : 'Points Burned',\n",
        "    'TransactionTime' : 'TransactionDate',\n",
        "    'EarnedPoints' : 'Base Earned Points',\n",
        "    'Area' : 'Types',\n",
        "    'ConceptName' : 'Concept',\n",
        "    'NumConceptName' : 'NumConcept'\n",
        "}, inplace=True)\n",
        "\n",
        "dfChannelG.drop(columns=['Address2'], axis=1, inplace=True)\n",
        "dfChannelG.rename(columns={\n",
        "    'MemberName' : 'Name',\n",
        "    'Address1' : 'Address',\n",
        "    'TotalPointsEarned' :  'Points Earned',\n",
        "    'TotalPointsBurned' : 'Points Burned',\n",
        "    'TransactionTime' : 'TransactionDate',\n",
        "    'StoreLocation_x' : 'StoreLocation',\n",
        "    'EarnedPoints' : 'Base Earned Points',\n",
        "    'ConceptName' : 'Types',\n",
        "    'StoreLocation_y' : 'Concept',\n",
        "    'NumStoreLocation' : 'NumConcept'\n",
        "}, inplace=True)\n",
        "\n",
        "dataGabunganB = pd.concat([dfChannelF,dfChannelG])\n",
        "\n",
        "# Concat Data All Channel\n",
        "dataGabungan = pd.concat([dataGabunganA,dataGabunganB])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Snap Data & Etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# For get data date date snap\n",
        "dataGabungan['Week'] = date_obj.isocalendar()[1]\n",
        "dataGabungan['Month'] = date_obj.month\n",
        "dataGabungan['Year'] = date_obj.year\n",
        "dataGabungan['DateSnap'] = date_obj\n",
        "\n",
        "# Reposition Column Form\n",
        "dataGabungan = dataGabungan[['Week', 'Month', 'Year', 'DateSnap','MemberID', 'LoyaltyMemberID', 'Name', 'BirthDate', 'Address', 'Phone',\n",
        "    'Email', 'EnrollmentDate', 'EnrollmentStore', 'Points Earned', 'Points Burned', 'TransactionDate', 'StoreLocation',\n",
        "    'Base Earned Points', 'TotalTransactions', 'Channels', 'Types', 'Concept', 'NumConcept']]\n",
        "\n",
        "# Drop duplicate by weekly\n",
        "dataGabungan.drop_duplicates(subset=['Week', 'MemberID'], inplace=True)\n",
        "\n",
        "# Left join data member to all status channel member\n",
        "dataGabungan = dataGabungan.merge(dfStatusGP,on='LoyaltyMemberID',how='left')\n",
        "\n",
        "# Change data type\n",
        "dataGabungan['LoyaltyMemberID'] = dataGabungan['LoyaltyMemberID'].astype('str')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Enroll Age Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "## Update Auto Fraud (Part 2) - Excel Part 3\n",
        "# Enroll Age Year\n",
        "def crtiX(x):\n",
        "    if x < 1 : return '1. <1 Year'\n",
        "    elif x < 2 : return '2. 1-2 Year'\n",
        "    elif x < 3 : return '3. 2-3 Year'\n",
        "    else : return '4. >3 Year'\n",
        "\n",
        "dataGabungan['EnrollYearsCrit'] = dataGabungan['EnrollmentDate'].apply(lambda x : date_obj - x.date()) / np.timedelta64(1, 'Y')\n",
        "dataGabungan['EnrollYearsCrit'] = dataGabungan['EnrollYearsCrit'].apply(lambda x : crtiX(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### True / False - Status Criteria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "dataGabungan['3TSS'] = dataGabungan['Status'].str.contains('3TSS')\n",
        "dataGabungan['E150K'] = dataGabungan['Status'].str.contains('E150K')\n",
        "dataGabungan['1T3DSS'] = dataGabungan['Status'].str.contains('1T3DSS')\n",
        "dataGabungan['4TDS'] = dataGabungan['Status'].str.contains('4TDS')\n",
        "dataGabungan['1ADC'] = dataGabungan['Status'].str.contains('1ADC')\n",
        "dataGabungan['SCDS'] = dataGabungan['Status'].str.contains('SCDS')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inject Data to Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Insert data weekly to data master (sql)\n",
        "dataGabungan.to_sql(con=connect_string_dwhdb,\n",
        "    name='dfFraudMasterFinal',\n",
        "    schema='gclub', # re-check\n",
        "    index=False,\n",
        "    if_exists='append')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Send Email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "import smtplib\n",
        "import base64\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.application import MIMEApplication\n",
        "\n",
        "def sendEmailSP(data):\n",
        "    # Email configuration\n",
        "    sender_email = \"dp-alert@notify.gtech.digital\"\n",
        "    sender_password = \"\"\n",
        "    receiver_email = \"ferdinand.tongga@gtech.digital, fazri.fatahillah@mapclub.com\"\n",
        "    #edited by rey 7/17/2023\n",
        "    # receiver_email = \"attariq.kasfilla@mapclub.com, reyki.seprianza@gtech.digital, fazri.fatahillah@mapclub.com\"\n",
        "    # cc_receiver_email = \"michael.danendra@mapclub.com, budi.santoso@mapclub.com, vincent.iskandar@gtech.digital, rian.andrea@gtech.digital, ferdinand.tongga@gtech.digital\"\n",
        "    subject = \"Fraud Detection - {0}\".format((date_obj).strftime(\"%Y-%m-%d\"))\n",
        "    body = \"Dear All, \\nBerikut results fraud detection per hari ini yang perlu segera di analisa\\n4 Detection = {0} Member\\n5 Detection = {1} Member\\n6 Detection = {2} Member\".format(data[data['NumStatus'] == 4]['MemberID'].nunique(),\n",
        "                                     data[data['NumStatus'] == 5]['MemberID'].nunique(),\n",
        "                                     data[data['NumStatus'] == 6]['MemberID'].nunique())\n",
        "\n",
        "    # Excel attachment configuration\n",
        "    attachment_path = 'DataFraudDetection.xlsx'\n",
        "\n",
        "    # Compose the email\n",
        "    msg = MIMEMultipart()\n",
        "    msg[\"From\"] = sender_email\n",
        "    msg[\"To\"] = receiver_email\n",
        "    msg[\"Subject\"] = subject\n",
        "    # msg[\"Cc\"] = cc_receiver_email\n",
        "\n",
        "    msg.attach(MIMEText(body, \"plain\"))\n",
        "\n",
        "    # Attach the Excel file\n",
        "    with open(attachment_path, \"rb\") as f:\n",
        "        attachment = MIMEApplication(f.read(), _subtype=\"xlsx\")\n",
        "        attachment.add_header(\"Content-Disposition\", \"attachment\", filename=attachment_path)\n",
        "        msg.attach(attachment)\n",
        "\n",
        "    # Send the email\n",
        "    with smtplib.SMTP('smtpdm-ap-southeast-1.aliyun.com', 80) as server:\n",
        "        # server.starttls()\n",
        "        server.login(sender_email, sender_password)\n",
        "        server.send_message(msg)\n",
        "        print(\"Email sent successfully!\")\n",
        "\n",
        "\n",
        "if True in (dataGabungan['NumStatus'].unique() >= 4):\n",
        "    saveToExcelForEmail = dataGabungan[dataGabungan['NumStatus'] >= 4].copy()\n",
        "    saveToExcelForEmail.to_excel('DataFraudDetection.xlsx', index=False)\n",
        "    sendEmailSP(saveToExcelForEmail)\n",
        "else : print('ngga ada')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%sh\n",
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%sh\n",
        "rm DataFraudDetection.xlsx"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "daily_update_fraud_(day)_seperated"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
